{
 "cells": [
  {
   "cell_type": "code",
   "id": "0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:35:04.751431Z",
     "start_time": "2025-04-24T12:35:04.613889Z"
    }
   },
   "source": [
    "\n",
    "import shutil\n",
    "shutil.rmtree('__pycache__', ignore_errors=True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix\n",
    "import importlib\n",
    "# Our functions\n",
    "from EvalFunctions import AUCEval, MMREval, nDCGEval\n",
    "from RecAlgs import MostPopBaseline, CollaborativeFiltering, Hybrid, News_Recommender_CBF\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 201
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "The parameters to select how to tun the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:35:05.754314Z",
     "start_time": "2025-04-24T12:35:05.608832Z"
    }
   },
   "source": [
    "# General\n",
    "TimeCutOffDays = 3              # How old the articles can be that we would consider recommending (older than X days are not considered)\n",
    "\n",
    "# Data selection                \n",
    "TrainingDataStartDate = 0       # From what day we want to collect data\n",
    "TrainingDataWindowSize = 2      # How many days of training data we want, 0 for all\n",
    "TestDataWindowSize = 1          # How many days of test data we want, 0 for all\n",
    "\n",
    "# Algorithm specifics \n",
    "TypeOfRecAlg = 0                # Which RecAlg we want to use 0-Pop, 1-Rand, 2-CBF, 3-CF, 4-Hybrid\n",
    "\n",
    "# Popular Baseline\n",
    "TimePenaltyPerHour = 0.1        # The percentage on penalty per hour the news gets\n",
    "TimePenaltyStart = 24           # After howmany hours in the past the penalty starts\n",
    "\n",
    "# Random Baseline\n",
    "MinScore = 0                    # Minimum score that can be given\n",
    "MaxScore = 1                    # Maximum score that can be given\n",
    "\n",
    "# Content based filtering\n",
    "\n",
    "# Collaborative filtering\n",
    "\n",
    "# Hybrid\n",
    "UsePopBaseline = False          # Whether to use Popularity baseline\n",
    "UseRandBaseLine = False         # Whether to use Random baseline\n",
    "UseCBF = True                   # Whether to use Content based filtering\n",
    "UseCF = True                    # Whether to use Collaborative filtering\n",
    "TakeMax = False                 # Whether to take the max between CBF and CF before applying weights\n",
    "Weights = [0.2, 0.4, 0.4]       # The weights for the different parts (in order of appearance above)\n"
   ],
   "outputs": [],
   "execution_count": 202
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Data selection"
   ]
  },
  {
   "cell_type": "code",
   "id": "90ec24fba2decf9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:35:08.630442Z",
     "start_time": "2025-04-24T12:35:08.497292Z"
    }
   },
   "source": [
    "def getAvailableArticles(GivenTime, AllArticles):\n",
    "    # Ensure the time column is in datetime format\n",
    "    AllArticles['ReleaseDate'] = pd.to_datetime(AllArticles['ReleaseDate'])\n",
    "    GivenTime = pd.to_datetime(GivenTime)\n",
    "\n",
    "    # Filter rows where time is less than or equal to the given time\n",
    "    return AllArticles[AllArticles['ReleaseDate'] >= GivenTime]\n",
    "\n",
    "def getPastBehaviors(GivenTime, AllBehaviors):\n",
    "    # Ensure the time column is in datetime format\n",
    "    AllBehaviors['DateTime'] = pd.to_datetime(AllBehaviors['DateTime'])\n",
    "    GivenTime = pd.to_datetime(GivenTime)\n",
    "\n",
    "    # Filter rows where time is less than or equal to the given time\n",
    "    return AllBehaviors[AllBehaviors['DateTime'] >= GivenTime], AllBehaviors[AllBehaviors['DateTime'] <= GivenTime]\n",
    "\n",
    "def getGroundTruth(FutureBehaviors, RequestedUserID):\n",
    "    ClickedArticles = []\n",
    "\n",
    "    # Count how many times the user appears\n",
    "    user_rows = [row for row in FutureBehaviors.itertuples(index=False) if str(row.UserID) == str(RequestedUserID)]\n",
    "\n",
    "    for row in user_rows:\n",
    "        if not isinstance(row.ClickData, str):\n",
    "            continue  # Skip if ClickData is not a string\n",
    "\n",
    "        for Click in row.ClickData.split(\" \"):\n",
    "            if Click.endswith(\"-1\"):\n",
    "                ClickedArticles.append(Click.replace(\"-1\", \"\"))\n",
    "\n",
    "    # print(f\"Ground truth for user {RequestedUserID}: {ClickedArticles}\")\n",
    "    return ClickedArticles\n",
    "\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 203
  },
  {
   "cell_type": "code",
   "id": "4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:35:14.486516Z",
     "start_time": "2025-04-24T12:35:09.282236Z"
    }
   },
   "source": [
    "# Add the first time the article has been seen in the behaviors as the Est_PublishedTime in the articles.\n",
    "AllTrainingData = pd.read_csv(\"../data/MINDsmall_train/behaviors.tsv\", sep=\"\\t\", header=None, names=[\"UserID\", \"DateTime\", \"History\", \"ClickData\"])\n",
    "AllValidationData = pd.read_csv(\"../data/MINDsmall_dev/behaviors.tsv\", sep=\"\\t\", header=None, names=[\"UserID\", \"DateTime\", \"History\", \"ClickData\"])\n",
    "AllData = pd.concat([AllTrainingData, AllValidationData], ignore_index=True)\n",
    "\n",
    "ArticlesTrain = pd.read_csv(\"../data/MINDsmall_train/news.tsv\", sep=\"\\t\", header=None, names=[\"NewsID\", \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\", \"TitleEntities\", \"AbstractEntities\"])\n",
    "ArticlesValidation = pd.read_csv(\"../data/MINDsmall_dev/news.tsv\", sep=\"\\t\", header=None, names=[\"NewsID\", \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\", \"TitleEntities\", \"AbstractEntities\"])\n",
    "AllArticles = pd.concat([ArticlesTrain, ArticlesValidation], ignore_index=True)\n",
    "\n",
    "ArticlesTrainWithTime = pd.read_csv(\"../data/NewsWithTime/small/TrainNewsWithTime.csv\")\n",
    "ArticlesValidationWithTime = pd.read_csv(\"../data/NewsWithTime/small/DevNewsWithTime.csv\")\n",
    "AllArticlesWithTime = pd.read_csv(\"../data/NewsWithTime/small/AllNewsWithTime.csv\")\n"
   ],
   "outputs": [],
   "execution_count": 204
  },
  {
   "cell_type": "code",
   "id": "771d16d894c0ce7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:05:55.762692Z",
     "start_time": "2025-04-24T12:05:55.633521Z"
    }
   },
   "source": [
    "#Maybe add something to reduce the amount of data??"
   ],
   "outputs": [],
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "id": "9f76e445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:05:56.566225Z",
     "start_time": "2025-04-24T12:05:56.432647Z"
    }
   },
   "source": [
    "# colab_filter = CollaborativeFiltering.CollaborativeFiltering(AllTrainingData, epochs=2)\n",
    "# \n",
    "# colab_filter.initialize()"
   ],
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:35:28.019834Z",
     "start_time": "2025-04-24T12:35:15.622779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_items = \"../data/MINDsmall_train/news.tsv\"\n",
    "path_user_behavior = \"../data/MINDsmall_train/behaviors.tsv\"\n",
    "\n",
    "recommender = News_Recommender_CBF.NewsRecommenderCBF(path_items, path_user_behavior)\n",
    "recommender.get_user_frame()"
   ],
   "id": "90d6b71889329449",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 ----------> ITEM data loaded successfully: 51282 records!\n",
      "01 ----------> USER data loaded successfully: 156965 records!\n",
      "02 ----------> Corpus created: 51282 documents!\n",
      "03 ----------> TF-IDF matrix created: 51282 documents, 167113 terms!\n",
      "04 ----------> Category matrix created: 51282 documents, 281 categories!\n",
      "05 ----------> Combined matrix created, shape: (51282, 167394)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           uID                   t  \\\n",
       "1       U13740 2019-11-11 09:05:58   \n",
       "2       U91836 2019-11-12 18:11:30   \n",
       "3       U73700 2019-11-14 07:01:48   \n",
       "4       U34670 2019-11-11 05:28:05   \n",
       "5        U8125 2019-11-12 16:11:21   \n",
       "...        ...                 ...   \n",
       "156961  U21593 2019-11-14 22:24:05   \n",
       "156962  U10123 2019-11-13 06:57:04   \n",
       "156963  U75630 2019-11-14 10:58:13   \n",
       "156964  U44625 2019-11-13 14:57:02   \n",
       "156965  U64800 2019-11-14 15:25:49   \n",
       "\n",
       "                                                ClickHist  \\\n",
       "1       N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
       "2       N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
       "3       N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
       "4       N45729 N2203 N871 N53880 N41375 N43142 N33013 ...   \n",
       "5                             N10078 N56514 N14904 N33740   \n",
       "...                                                   ...   \n",
       "156961  N7432 N58559 N1954 N43353 N14343 N13008 N28833...   \n",
       "156962  N9803 N104 N24462 N57318 N55743 N40526 N31726 ...   \n",
       "156963  N29898 N59704 N4408 N9803 N53644 N26103 N812 N...   \n",
       "156964  N4118 N47297 N3164 N43295 N6056 N38747 N42973 ...   \n",
       "156965                                      N22997 N48742   \n",
       "\n",
       "                                                   ImpLog  \n",
       "1                                       N55689-1 N35729-0  \n",
       "2       N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...  \n",
       "3       N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...  \n",
       "4                     N35729-0 N33632-0 N49685-1 N27581-0  \n",
       "5       N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...  \n",
       "...                                                   ...  \n",
       "156961  N2235-0 N22975-0 N64037-0 N47652-0 N11378-0 N4...  \n",
       "156962  N3841-0 N61571-0 N58813-0 N28213-0 N4428-0 N25...  \n",
       "156963  N55913-0 N62318-0 N53515-0 N10960-0 N9135-0 N5...  \n",
       "156964  N6219-0 N3663-0 N31147-0 N58363-0 N4107-0 N457...  \n",
       "156965                N61233-0 N33828-1 N19661-0 N41934-0  \n",
       "\n",
       "[156965 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uID</th>\n",
       "      <th>t</th>\n",
       "      <th>ClickHist</th>\n",
       "      <th>ImpLog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U13740</td>\n",
       "      <td>2019-11-11 09:05:58</td>\n",
       "      <td>N55189 N42782 N34694 N45794 N18445 N63302 N104...</td>\n",
       "      <td>N55689-1 N35729-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U91836</td>\n",
       "      <td>2019-11-12 18:11:30</td>\n",
       "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
       "      <td>N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U73700</td>\n",
       "      <td>2019-11-14 07:01:48</td>\n",
       "      <td>N10732 N25792 N7563 N21087 N41087 N5445 N60384...</td>\n",
       "      <td>N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U34670</td>\n",
       "      <td>2019-11-11 05:28:05</td>\n",
       "      <td>N45729 N2203 N871 N53880 N41375 N43142 N33013 ...</td>\n",
       "      <td>N35729-0 N33632-0 N49685-1 N27581-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U8125</td>\n",
       "      <td>2019-11-12 16:11:21</td>\n",
       "      <td>N10078 N56514 N14904 N33740</td>\n",
       "      <td>N39985-0 N36050-0 N16096-0 N8400-1 N22407-0 N6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156961</th>\n",
       "      <td>U21593</td>\n",
       "      <td>2019-11-14 22:24:05</td>\n",
       "      <td>N7432 N58559 N1954 N43353 N14343 N13008 N28833...</td>\n",
       "      <td>N2235-0 N22975-0 N64037-0 N47652-0 N11378-0 N4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156962</th>\n",
       "      <td>U10123</td>\n",
       "      <td>2019-11-13 06:57:04</td>\n",
       "      <td>N9803 N104 N24462 N57318 N55743 N40526 N31726 ...</td>\n",
       "      <td>N3841-0 N61571-0 N58813-0 N28213-0 N4428-0 N25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156963</th>\n",
       "      <td>U75630</td>\n",
       "      <td>2019-11-14 10:58:13</td>\n",
       "      <td>N29898 N59704 N4408 N9803 N53644 N26103 N812 N...</td>\n",
       "      <td>N55913-0 N62318-0 N53515-0 N10960-0 N9135-0 N5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156964</th>\n",
       "      <td>U44625</td>\n",
       "      <td>2019-11-13 14:57:02</td>\n",
       "      <td>N4118 N47297 N3164 N43295 N6056 N38747 N42973 ...</td>\n",
       "      <td>N6219-0 N3663-0 N31147-0 N58363-0 N4107-0 N457...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156965</th>\n",
       "      <td>U64800</td>\n",
       "      <td>2019-11-14 15:25:49</td>\n",
       "      <td>N22997 N48742</td>\n",
       "      <td>N61233-0 N33828-1 N19661-0 N41934-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156965 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:35:33.244279Z",
     "start_time": "2025-04-24T12:35:29.857325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PopularityDict = {}\n",
    "for row in AllData.itertuples(index=False):\n",
    "    for click in row.ClickData.split(\" \"):  # split string of clicks\n",
    "        if click.endswith(\"-1\"):  # Only clicked articles\n",
    "            ArticleID = click.replace(\"-1\", \"\")\n",
    "            PopularityDict[ArticleID] = PopularityDict.get(ArticleID, 0) + 1\n",
    "# Assuming it's a dict: {news_id: count}\n",
    "PopularityDict = sorted(PopularityDict.items(), key=lambda x: x[1], reverse=True)\n"
   ],
   "id": "6896e19c2927f278",
   "outputs": [],
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "id": "e21c7bcb7c46e836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T12:36:47.626379Z",
     "start_time": "2025-04-24T12:36:41.205391Z"
    }
   },
   "source": [
    "#Main loop\n",
    "TypeOfRecAlg = 0\n",
    "#Assume we use the past behaviors we have to predict the click behavior on the test set (-1's aka clicked articles)\n",
    "#We hope our recommendations include these articles\n",
    "TotalAUCEvalScore = 0\n",
    "TotalMMREEvalScore = 0\n",
    "TotalNDCGEvalScore = 0\n",
    "i=0\n",
    "amountOfColdStarts = 0\n",
    "for _, instance in tqdm(AllValidationData.iterrows(), total=len(AllValidationData), desc=\"Processing Instances\"):\n",
    "    # Get necessary parameters\n",
    "    UserID = instance['UserID']\n",
    "    Time = pd.to_datetime(instance['DateTime'])\n",
    "    AvailableNews = getAvailableArticles(Time, ArticlesValidationWithTime)\n",
    "    PastBehaviors, FutureBehaviors = getPastBehaviors(Time, AllValidationData)\n",
    "    AvailableNews.loc[:, 'ReleaseDate'] = pd.to_datetime(AvailableNews['ReleaseDate'])\n",
    "    \n",
    "    GT = getGroundTruth(FutureBehaviors, UserID)\n",
    "    # skip user if there is no future data for this user\n",
    "    if len(GT) == 0:\n",
    "        continue\n",
    "    # Run the selected RecAlg\n",
    "    if TypeOfRecAlg == 0:\n",
    "        # PossibleArticles, CurrentTime, GlobalPopularity, TimePenaltyPerHour, TimePenaltyStart\n",
    "        TopTenArticleRecommendations = MostPopBaseline.RecommendMostPopular(AvailableNews, Time, PopularityDict, TimePenaltyPerHour, TimePenaltyStart)\n",
    "    elif TypeOfRecAlg == 1:\n",
    "        TopTenArticleRecommendations = recommender.recommend(UserID, 10)\n",
    "\n",
    "    # elif TypeOfRecAlg == 2:\n",
    "    #     TopTenArticleRecommendations = colab_filter.getRecommended(UserID, k=10)\n",
    "\n",
    "    elif TypeOfRecAlg == 3:\n",
    "        TopTenArticleRecommendations = Hybrid()\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    # For cold start\n",
    "    if len(TopTenArticleRecommendations) == 0:\n",
    "        amountOfColdStarts += 1\n",
    "        TopTenArticleRecommendations = MostPopBaseline.RecommendMostPopular(AvailableNews, PastBehaviors, \n",
    "                                                                            Time, TimePenaltyPerHour, TimePenaltyStart)\n",
    "        \n",
    "    # Calculate evaluation scores\n",
    "    AUCScore = AUCEval.AUCEval(TopTenArticleRecommendations, GT)\n",
    "    MMREScore = MMREval.MMREval(TopTenArticleRecommendations, GT)\n",
    "    NDCGScore = nDCGEval.nDCG(TopTenArticleRecommendations, GT)\n",
    "    \n",
    "    # Print the scores for the current user and generation\n",
    "    # print(f\"Generation {i}: User {UserID} - AUC: {AUCScore}, MMRE: {MMREScore}, NDCG: {NDCGScore}\")\n",
    "    \n",
    "    # Accumulate the total scores\n",
    "    TotalAUCEvalScore += AUCScore\n",
    "    TotalMMREEvalScore += MMREScore\n",
    "    TotalNDCGEvalScore += NDCGScore\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "\n",
    "AvgAUCScore = TotalAUCEvalScore/i\n",
    "AvgMMREScore = TotalMMREEvalScore/i\n",
    "AvgNDCGScore = TotalNDCGEvalScore/i\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Instances:   0%|          | 28/73152 [00:06<4:23:49,  4.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[209], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m AvailableNews \u001B[38;5;241m=\u001B[39m getAvailableArticles(Time, ArticlesValidationWithTime)\n\u001B[0;32m     15\u001B[0m PastBehaviors, FutureBehaviors \u001B[38;5;241m=\u001B[39m getPastBehaviors(Time, AllValidationData)\n\u001B[1;32m---> 16\u001B[0m AvailableNews\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReleaseDate\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_datetime\u001B[49m\u001B[43m(\u001B[49m\u001B[43mAvailableNews\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mReleaseDate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m GT \u001B[38;5;241m=\u001B[39m getGroundTruth(FutureBehaviors, UserID)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# skip user if there is no future data for this user\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001B[0m, in \u001B[0;36mto_datetime\u001B[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001B[0m\n\u001B[0;32m   1061\u001B[0m             result \u001B[38;5;241m=\u001B[39m arg\u001B[38;5;241m.\u001B[39mtz_localize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutc\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1062\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, ABCSeries):\n\u001B[1;32m-> 1063\u001B[0m     cache_array \u001B[38;5;241m=\u001B[39m \u001B[43m_maybe_cache\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_listlike\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1064\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m cache_array\u001B[38;5;241m.\u001B[39mempty:\n\u001B[0;32m   1065\u001B[0m         result \u001B[38;5;241m=\u001B[39m arg\u001B[38;5;241m.\u001B[39mmap(cache_array)\n",
      "File \u001B[1;32mC:\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:239\u001B[0m, in \u001B[0;36m_maybe_cache\u001B[1;34m(arg, format, cache, convert_listlike)\u001B[0m\n\u001B[0;32m    235\u001B[0m cache_array \u001B[38;5;241m=\u001B[39m Series(dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mobject\u001B[39m)\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache:\n\u001B[0;32m    238\u001B[0m     \u001B[38;5;66;03m# Perform a quicker unique check\u001B[39;00m\n\u001B[1;32m--> 239\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mshould_cache\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m cache_array\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arg, (np\u001B[38;5;241m.\u001B[39mndarray, ExtensionArray, Index, ABCSeries)):\n",
      "File \u001B[1;32mC:\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:201\u001B[0m, in \u001B[0;36mshould_cache\u001B[1;34m(arg, unique_share, check_count)\u001B[0m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m unique_share \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munique_share must be in next bounds: (0; 1)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;66;03m# We can't cache if the items are not hashable.\u001B[39;00m\n\u001B[1;32m--> 201\u001B[0m     unique_elements \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mislice\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_count\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "id": "f92b2ae242dfc0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T09:47:41.744855Z",
     "start_time": "2025-04-24T09:47:41.555812Z"
    }
   },
   "source": [
    "# Average Evaluation\n",
    "\n",
    "# Look at the results, and evaluate them with the different evaluation functions"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "57c46e905232c557"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
