{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "# Our functions\n",
    "from EvalFunctions import AUCEval, MMREval, nDCGEval\n",
    "from RecAlgs import CollaborativeFiltering, MostPopBaseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "The parameters to select how to tun the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "TimeCutOffDays = 3              # How old the articles can be that we would consider recommending (older than X days are not considered)\n",
    "\n",
    "# Data selection                \n",
    "TrainingDataStartDate = 0       # From what day we want to collect data\n",
    "TrainingDataWindowSize = 2      # How many days of training data we want, 0 for all\n",
    "TestDataWindowSize = 1          # How many days of test data we want, 0 for all\n",
    "\n",
    "# Algorithm specifics \n",
    "TypeOfRecAlg = 3                # Which RecAlg we want to use 0-Pop, 1-Rand, 2-CBF, 3-CF, 4-Hybrid\n",
    "\n",
    "# Popular Baseline\n",
    "TimePenaltyPerHour = 0.1        # The percentage on penalty per hour the news gets\n",
    "TimePenaltyStart = 24           # After howmany hours in the past the penalty starts\n",
    "\n",
    "# Random Baseline\n",
    "MinScore = 0                    # Minimum score that can be given\n",
    "MaxScore = 1                    # Maximum score that can be given\n",
    "\n",
    "# Content based filtering\n",
    "\n",
    "# Collaborative filtering\n",
    "\n",
    "# Hybrid\n",
    "UsePopBaseline = False          # Whether to use Popularity baseline\n",
    "UseRandBaseLine = False         # Whether to use Random baseline\n",
    "UseCBF = True                   # Whether to use Content based filtering\n",
    "UseCF = True                    # Whether to use Collaborative filtering\n",
    "TakeMax = False                 # Whether to take the max between CBF and CF before applying weights\n",
    "Weights = [0.2, 0.4, 0.4]       # The weights for the different parts (in order of appearance above)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ec24fba2decf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvailableArticles(GivenTime, AllArticles):\n",
    "    # Ensure the time column is in datetime format\n",
    "    AllArticles['ReleaseDate'] = pd.to_datetime(AllArticles['ReleaseDate'])\n",
    "    GivenTime = pd.to_datetime(GivenTime)\n",
    "\n",
    "    # Filter rows where time is less than or equal to the given time\n",
    "    return AllArticles[AllArticles['ReleaseDate'] >= GivenTime]\n",
    "\n",
    "def getPastBehaviors(GivenTime, AllBehaviors):\n",
    "    # Ensure the time column is in datetime format\n",
    "    AllBehaviors['DateTime'] = pd.to_datetime(AllBehaviors['DateTime'])\n",
    "    GivenTime = pd.to_datetime(GivenTime)\n",
    "\n",
    "    # Filter rows where time is less than or equal to the given time\n",
    "    return AllBehaviors[AllBehaviors['DateTime'] >= GivenTime], AllBehaviors[AllBehaviors['DateTime'] < GivenTime]\n",
    "\n",
    "def getGroundTruth(FutureBehaviors, RequestedUserID):\n",
    "    UserFuture = {ClickData for UserID, DateTime, History, ClickData in FutureBehaviors if UserID == RequestedUserID}\n",
    "    ClickedArticles = []\n",
    "    for ClickData in UserFuture:\n",
    "        for Article in ClickData:\n",
    "            if Article.endswith(\"-1\"):\n",
    "                Article = Article.removesuffix(\"-1\")\n",
    "                if Article not in ClickedArticles:\n",
    "                    ClickedArticles.append(Article)\n",
    "                \n",
    "    return ClickedArticles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first time the article has been seen in the behaviors as the Est_PublishedTime in the articles.\n",
    "AllTrainingData = pd.read_csv(\"../data/MINDsmall_train/behaviors.tsv\", sep=\"\\t\", header=None, names=[\"UserID\", \"DateTime\", \"History\", \"ClickData\"])\n",
    "AllValidationData = pd.read_csv(\"../data/MINDsmall_dev/behaviors.tsv\", sep=\"\\t\", header=None, names=[\"UserID\", \"DateTime\", \"History\", \"ClickData\"])\n",
    "AllData = pd.concat([AllTrainingData, AllValidationData], ignore_index=True)\n",
    "\n",
    "ArticlesTrain = pd.read_csv(\"../data/MINDsmall_train/news.tsv\", sep=\"\\t\", header=None, names=[\"NewsID\", \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\", \"TitleEntities\", \"AbstractEntities\"])\n",
    "ArticlesValidation = pd.read_csv(\"../data/MINDsmall_dev/news.tsv\", sep=\"\\t\", header=None, names=[\"NewsID\", \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\", \"TitleEntities\", \"AbstractEntities\"])\n",
    "AllArticles = pd.concat([ArticlesTrain, ArticlesValidation], ignore_index=True)\n",
    "\n",
    "ArticlesTrainWithTime = pd.read_csv(\"../data/NewsWithTime/small/TrainNewsWithTime.csv\")\n",
    "ArticlesValidationWithTime = pd.read_csv(\"../data/NewsWithTime/small/DevNewsWithTime.csv\")\n",
    "AllArticlesWithTime = pd.read_csv(\"../data/NewsWithTime/small/AllNewsWithTime.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771d16d894c0ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maybe add something to reduce the amount of data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f76e445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing collaborative filtering...\n",
      "apply start\n",
      "explode start\n",
      "sparse matrix start\n",
      "Starting ALS using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repo\\recommendersystems\\RecommenderSystems\\Program\\RecAlgs\\CollaborativeFiltering.py:78: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  indices=torch.tensor([rows, cols], device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction_sparse.shape:  torch.Size([50000, 33196])\n",
      "user_embeddings.shape, item_embeddings.shape:  torch.Size([50000, 3]) torch.Size([33196, 3])\n",
      "training start\n",
      "Epoch 1/4, Loss: 57.603092193603516\n",
      "Epoch 2/4, Loss: 55.81801223754883\n",
      "Epoch 3/4, Loss: 55.38041305541992\n",
      "Epoch 4/4, Loss: 55.25794219970703\n"
     ]
    }
   ],
   "source": [
    "colab_filter = CollaborativeFiltering.CollaborativeFiltering(AllTrainingData, epochs=4)\n",
    "\n",
    "colab_filter.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b54825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RecAlgs.CollaborativeFiltering.CollaborativeFiltering at 0x28570c6fbc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colab_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e21c7bcb7c46e836",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AllValidationData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m TotalNDCGEvalScore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m \u001b[43mAllValidationData\u001b[49m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Get necessary parameters\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     UserID \u001b[38;5;241m=\u001b[39m instance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUserID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m     Time \u001b[38;5;241m=\u001b[39m instance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AllValidationData' is not defined"
     ]
    }
   ],
   "source": [
    "#Main loop\n",
    "#Assume we use the past behaviors we have to predict the click behavior on the test set (-1's aka clicked articles)\n",
    "#We hope our recommendations include these articles\n",
    "TotalAUCEvalScore = 0\n",
    "TotalMMREEvalScore = 0\n",
    "TotalNDCGEvalScore = 0\n",
    "i=0\n",
    "for instance in AllValidationData:\n",
    "    # Get necessary parameters\n",
    "    UserID = instance['UserID']\n",
    "    Time = instance['DateTime']\n",
    "    AvailableNews = getAvailableArticles(Time, ArticlesValidationWithTime)\n",
    "    PastBehaviors, FutureBehaviors = getPastBehaviors(Time, AllValidationData)\n",
    "\n",
    "    # Run the selected RecAlg\n",
    "    if TypeOfRecAlg == 0:\n",
    "        TopTenArticleRecommendations = MostPopBaseline.ReccomendMostPopular(AvailableNews, PastBehaviors, \n",
    "                                                                            Time, TimePenaltyPerHour, TimePenaltyStart)\n",
    "    elif TypeOfRecAlg == 1:\n",
    "        TopTenArticleRecommendations = RecAlgs.RandomBaseline()\n",
    "    elif TypeOfRecAlg == 2:\n",
    "        TopTenArticleRecommendations = RecAlgs.ContentBasedFiltering()    \n",
    "    elif TypeOfRecAlg == 3:\n",
    "        TopTenArticleRecommendations = colab_filter.getRecommended(AvailableNews, UserID, k=10)\n",
    "        # TopTenArticleRecommendations = RecAlgs.CollaborativeFiltering()\n",
    "\n",
    "    elif TypeOfRecAlg == 4:\n",
    "        TopTenArticleRecommendations = RecAlgs.Hybrid()\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    TotalAUCEvalScore += AUCEval.AUCEval(TopTenArticleRecommendations, getGroundTruth(FutureBehaviors, UserID))\n",
    "    TotalMMREEvalScore += MMREval.MMREval(TopTenArticleRecommendations, getGroundTruth(FutureBehaviors, UserID))\n",
    "    TotalNDCGEvalScore += nDCGEval.nDCG(TopTenArticleRecommendations, getGroundTruth(FutureBehaviors, UserID))\n",
    "    i+=1\n",
    "\n",
    "    break\n",
    "\n",
    "AvgAUCScore = TotalAUCEvalScore/i\n",
    "AvgMMREScore = TotalMMREEvalScore/i\n",
    "AvgNDCGScore = TotalNDCGEvalScore/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b2ae242dfc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Evaluation\n",
    "\n",
    "# Look at the results, and evaluate them with the different evaluation functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
