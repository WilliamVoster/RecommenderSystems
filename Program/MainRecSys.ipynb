{
 "cells": [
  {
   "cell_type": "code",
   "id": "0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T11:53:03.832847Z",
     "start_time": "2025-04-25T11:53:02.444844Z"
    }
   },
   "source": [
    "\n",
    "import shutil\n",
    "shutil.rmtree('__pycache__', ignore_errors=True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix\n",
    "import importlib\n",
    "# Our functions\n",
    "from EvalFunctions import AUCEval, MMREval, nDCGEval\n",
    "from RecAlgs import MostPopBaseline, CollaborativeFiltering, Hybrid, News_Recommender_CBF\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "The parameters to select how to tun the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T11:53:05.640782Z",
     "start_time": "2025-04-25T11:53:05.527486Z"
    }
   },
   "source": [
    "# General\n",
    "TimeCutOffDays = 3              # How old the articles can be that we would consider recommending (older than X days are not considered)\n",
    "AmountToPredict = 10\n",
    "\n",
    "# Data selection                \n",
    "TrainingDataStartDate = 0       # From what day we want to collect data\n",
    "TrainingDataWindowSize = 2      # How many days of training data we want, 0 for all\n",
    "TestDataWindowSize = 1          # How many days of test data we want, 0 for all\n",
    "\n",
    "# Algorithm specifics \n",
    "TypeOfRecAlg = 0                # Which RecAlg we want to use 0-Pop, 1-Rand, 2-CBF, 3-CF, 4-Hybrid\n",
    "\n",
    "# Popular Baseline\n",
    "TimePenaltyPerHour = 0.1        # The percentage on penalty per hour the news gets\n",
    "TimePenaltyStart = 24           # After howmany hours in the past the penalty starts\n",
    "\n",
    "# Random Baseline\n",
    "MinScore = 0                    # Minimum score that can be given\n",
    "MaxScore = 1                    # Maximum score that can be given\n",
    "\n",
    "# Content based filtering\n",
    "\n",
    "# Collaborative filtering\n",
    "\n",
    "# Hybrid\n",
    "UsePopBaseline = False          # Whether to use Popularity baseline\n",
    "UseRandBaseLine = False         # Whether to use Random baseline\n",
    "UseCBF = True                   # Whether to use Content based filtering\n",
    "UseCF = True                    # Whether to use Collaborative filtering\n",
    "TakeMax = False                 # Whether to take the max between CBF and CF before applying weights\n",
    "Weights = [0.2, 0.4, 0.4]       # The weights for the different parts (in order of appearance above)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Data selection"
   ]
  },
  {
   "cell_type": "code",
   "id": "90ec24fba2decf9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T11:53:07.509436Z",
     "start_time": "2025-04-25T11:53:07.398412Z"
    }
   },
   "source": [
    "def getGroundTruth(FutureBehaviors, RequestedUserID, CurrentInstanceClickData):\n",
    "    # Filter only relevant rows\n",
    "    UserData = FutureBehaviors[FutureBehaviors['UserID'] == RequestedUserID]\n",
    "    # Extract clicked articles\n",
    "    ClickedArticles = []\n",
    "    for clicks in UserData['ClickData']:\n",
    "        ClickedArticles.extend(\n",
    "            click.replace(\"-1\", \"\") for click in clicks.split(\" \") if click.endswith(\"-1\")\n",
    "        )\n",
    "    ClickedArticles.extend(\n",
    "        CurrentInstanceClickData.replace(\"-1\", \"\") for aclick in CurrentInstanceClickData.split(\" \") if aclick.endswith(\"-1\")\n",
    "    )\n",
    "    return ClickedArticles\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T11:53:13.194423Z",
     "start_time": "2025-04-25T11:53:08.334644Z"
    }
   },
   "source": [
    "# Add the first time the article has been seen in the behaviors as the Est_PublishedTime in the articles.\n",
    "AllTrainingData = pd.read_csv(\"../data/MINDsmall_train/behaviors.tsv\", sep=\"\\t\", header=None, names=[\"UserID\", \"DateTime\", \"History\", \"ClickData\"])\n",
    "AllValidationData = pd.read_csv(\"../data/MINDsmall_dev/behaviors.tsv\", sep=\"\\t\", header=None, names=[\"UserID\", \"DateTime\", \"History\", \"ClickData\"])\n",
    "AllData = pd.concat([AllTrainingData, AllValidationData], ignore_index=True)\n",
    "\n",
    "ArticlesTrain = pd.read_csv(\"../data/MINDsmall_train/news.tsv\", sep=\"\\t\", header=None, names=[\"NewsID\", \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\", \"TitleEntities\", \"AbstractEntities\"])\n",
    "ArticlesValidation = pd.read_csv(\"../data/MINDsmall_dev/news.tsv\", sep=\"\\t\", header=None, names=[\"NewsID\", \"Category\", \"SubCategory\", \"Title\", \"Abstract\", \"URL\", \"TitleEntities\", \"AbstractEntities\"])\n",
    "AllArticles = pd.concat([ArticlesTrain, ArticlesValidation], ignore_index=True)\n",
    "\n",
    "ArticlesTrainWithTime = pd.read_csv(\"../data/NewsWithTime/small/TrainNewsWithTime.csv\")\n",
    "ArticlesValidationWithTime = pd.read_csv(\"../data/NewsWithTime/small/DevNewsWithTime.csv\")\n",
    "AllArticlesWithTime = pd.read_csv(\"../data/NewsWithTime/small/AllNewsWithTime.csv\")\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "771d16d894c0ce7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T11:53:18.595760Z",
     "start_time": "2025-04-25T11:53:18.489839Z"
    }
   },
   "source": [
    "#Maybe add something to reduce the amount of data??"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "9f76e445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T11:55:09.909213Z",
     "start_time": "2025-04-25T11:53:19.519084Z"
    }
   },
   "source": [
    "colab_filter = CollaborativeFiltering.CollaborativeFiltering(AllTrainingData, epochs=2)\n",
    "\n",
    "colab_filter.initialize()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing collaborative filtering...\n",
      "apply start\n",
      "explode start\n",
      "sparse matrix start\n",
      "Starting ALS using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Storm\\PycharmProjects\\RecommenderSystems\\Program\\RecAlgs\\CollaborativeFiltering.py:78: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  indices=torch.tensor([rows, cols], device=device),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction_sparse.shape:  torch.Size([50000, 33196])\n",
      "user_embeddings.shape, item_embeddings.shape:  torch.Size([50000, 3]) torch.Size([33196, 3])\n",
      "training start\n",
      "Epoch 1/2, Loss: 57.583282470703125\n",
      "Epoch 2/2, Loss: 55.75069046020508\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:00:48.829210Z",
     "start_time": "2025-04-25T12:00:40.663179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_items = \"../data/MINDsmall_train/news.tsv\"\n",
    "path_user_behavior = \"../data/MINDsmall_train/behaviors.tsv\"\n",
    "\n",
    "recommender = News_Recommender_CBF.NewsRecommenderCBF(path_items, path_user_behavior)"
   ],
   "id": "90d6b71889329449",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 ----------> ITEM data loaded successfully: 51282 records!\n",
      "01 ----------> USER data loaded successfully: 156965 records!\n",
      "02 ----------> Corpus created: 51282 documents!\n",
      "03 ----------> TF-IDF matrix created: 51282 documents, 167113 terms!\n",
      "04 ----------> Category matrix created: 51282 documents, 281 categories!\n",
      "05 ----------> Combined matrix created, shape: (51282, 167394)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:01:17.243921Z",
     "start_time": "2025-04-25T12:01:15.215848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PopularityDict = {}\n",
    "for row in AllData.itertuples(index=False):\n",
    "    for click in row.ClickData.split(\" \"):  # split string of clicks\n",
    "        if click.endswith(\"-1\"):  # Only clicked articles\n",
    "            ArticleID = click.replace(\"-1\", \"\")\n",
    "            PopularityDict[ArticleID] = PopularityDict.get(ArticleID, 0) + 1\n",
    "PopularityDict = sorted(PopularityDict.items(), key=lambda x: x[1], reverse=True)\n"
   ],
   "id": "6896e19c2927f278",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e21c7bcb7c46e836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:29:07.995915Z",
     "start_time": "2025-04-25T12:27:19.072986Z"
    }
   },
   "source": [
    "#Main loop\n",
    "TypeOfRecAlg = 1\n",
    "#Assume we use the past behaviors we have to predict the click behavior on the test set (-1's aka clicked articles)\n",
    "#We hope our recommendations include these articles\n",
    "TotalAUCEvalScore = 0\n",
    "TotalMMREEvalScore = 0\n",
    "TotalNDCGEvalScore = 0\n",
    "i=0\n",
    "amountOfColdStarts = 0\n",
    "\n",
    "# Preprocessing before the loop \n",
    "ArticlesValidationWithTime = ArticlesValidationWithTime.sort_values('ReleaseDate').reset_index(drop=True)\n",
    "ArticlesValidationWithTime['ReleaseDate'] = pd.to_datetime(ArticlesValidationWithTime['ReleaseDate'])\n",
    "ReleaseDates = pd.to_datetime(ArticlesValidationWithTime['ReleaseDate'].values)\n",
    "\n",
    "# Sample set amount of instances in validation\n",
    "AllValidationData = AllValidationData.sample(n=1000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "AllBehaviors = AllValidationData.sort_values('DateTime').reset_index(drop=True)\n",
    "AllBehaviors['DateTime'] = pd.to_datetime(AllBehaviors['DateTime'])\n",
    "AllTimes = pd.to_datetime(AllBehaviors['DateTime'].values)\n",
    "\n",
    "for _, instance in tqdm(AllValidationData.iterrows(), total=len(AllValidationData), desc=\"Processing Instances\"):\n",
    "    # Get necessary parameters\n",
    "    UserID = instance['UserID']\n",
    "    Time = pd.to_datetime(instance['DateTime'])\n",
    "    cutoff_index = ReleaseDates.searchsorted(Time, side='right')\n",
    "    AvailableNews = ArticlesValidationWithTime.iloc[:cutoff_index]\n",
    "    \n",
    "    \n",
    "    future_start_idx = AllTimes.searchsorted(Time, side='left')\n",
    "    FutureBehaviors = AllBehaviors.iloc[future_start_idx:]\n",
    "    GT = getGroundTruth(FutureBehaviors, UserID, instance['ClickData'])\n",
    "    \n",
    "    # skip user if there is no future data for this user\n",
    "    if len(GT) == 0:\n",
    "        print(\"skipped user\")\n",
    "        continue\n",
    "        \n",
    "    # Run the selected RecAlg\n",
    "    if TypeOfRecAlg == 0:\n",
    "        # PossibleArticles, CurrentTime, GlobalPopularity, TimePenaltyPerHour, TimePenaltyStart\n",
    "        TopTenArticleRecommendations = MostPopBaseline.RecommendMostPopular(AvailableNews, Time, PopularityDict, TimePenaltyPerHour, TimePenaltyStart, AmountToPredict)\n",
    "    elif TypeOfRecAlg == 1:\n",
    "        TopTenArticleRecommendations = recommender.recommend(UserID, AmountToPredict)\n",
    "\n",
    "    elif TypeOfRecAlg == 2:\n",
    "        TopTenArticleRecommendations = colab_filter.getRecommended(UserID, k=AmountToPredict)\n",
    "\n",
    "    elif TypeOfRecAlg == 3:\n",
    "        PopRec = MostPopBaseline.RecommendMostPopular(AvailableNews, Time, PopularityDict, TimePenaltyPerHour, TimePenaltyStart, -1)\n",
    "        CFRec = colab_filter.getRecommended(UserID, -1)\n",
    "        CBRRec = recommender.recommend(UserID, -1)\n",
    "        TopTenArticleRecommendations = Hybrid.HybridRecommendations(PopRec, CFRec, CBRRec, Weights, AmountToPredict)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    # For cold start\n",
    "    if len(TopTenArticleRecommendations) == 0:\n",
    "        amountOfColdStarts += 1\n",
    "        TopTenArticleRecommendations = MostPopBaseline.RecommendMostPopular(AvailableNews, Time, PopularityDict, TimePenaltyPerHour, TimePenaltyStart, AmountToPredict)\n",
    "        \n",
    "    # Calculate evaluation scores\n",
    "    AUCScore = AUCEval.AUCEval(TopTenArticleRecommendations, GT)\n",
    "    MMREScore = MMREval.MMREval(TopTenArticleRecommendations, GT)\n",
    "    NDCGScore = nDCGEval.nDCG(TopTenArticleRecommendations, GT)\n",
    "    \n",
    "    # Print the scores for the current user and generation\n",
    "    # print(f\"Generation {i}: User {UserID} - AUC: {AUCScore}, MMRE: {MMREScore}, NDCG: {NDCGScore}\")\n",
    "    \n",
    "    # Accumulate the total scores\n",
    "    TotalAUCEvalScore += AUCScore\n",
    "    TotalMMREEvalScore += MMREScore\n",
    "    TotalNDCGEvalScore += NDCGScore\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "\n",
    "AvgAUCScore = TotalAUCEvalScore/i\n",
    "AvgMMREScore = TotalMMREEvalScore/i\n",
    "AvgNDCGScore = TotalNDCGEvalScore/i\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Instances: 100%|██████████| 1000/1000 [01:48<00:00,  9.21it/s]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "f92b2ae242dfc0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:29:15.262554Z",
     "start_time": "2025-04-25T12:29:15.156023Z"
    }
   },
   "source": [
    "# Average Evaluation\n",
    "print(f\"Average AUC Score: {AvgAUCScore:.20f}\")\n",
    "print(f\"Average MMR Score: {AvgMMREScore:.20f}\")\n",
    "print(f\"Average NDCG Score: {AvgNDCGScore:.20f}\")\n",
    "# Look at the results, and evaluate them with the different evaluation functions"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC Score: 0.12149999999999999689\n",
      "Average MMR Score: 0.10016309674075851710\n",
      "Average NDCG Score: 0.14204373271291267922\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "57c46e905232c557"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
